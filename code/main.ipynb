{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iwasakimao/workspace/mufj_signate_mywork/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"intfloat/multilingual-e5-large\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModel.from_pretrained(MODEL_ID).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>timeToReply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Banyak bug nya!!!! Dikit² eror terus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Hello BANK Friend, sorry for the issues you’re...</td>\n",
       "      <td>0 days 05:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cash deposit menu does not appear Even after u...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Hello, Friend BANK. Kindly upgrade the BANKApp...</td>\n",
       "      <td>0 days 14:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sangat membantu</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Hello BANK Customer, we appreciate you using t...</td>\n",
       "      <td>0 days 00:41:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Very cool</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Hello BANK Friend, we appreciate your review. ...</td>\n",
       "      <td>0 days 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Improved</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Hello BANK Friend, we appreciate your feedback...</td>\n",
       "      <td>0 days 15:05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  score  \\\n",
       "0           0               Banyak bug nya!!!! Dikit² eror terus      0   \n",
       "1           1  Cash deposit menu does not appear Even after u...      2   \n",
       "2           2                                    Sangat membantu      4   \n",
       "3           3                                          Very cool      4   \n",
       "4           4                                           Improved      4   \n",
       "\n",
       "   thumbsUpCount  reviewCreatedVersion  \\\n",
       "0              0                  33.0   \n",
       "1              0                  32.0   \n",
       "2              0                  33.0   \n",
       "3              0                  33.0   \n",
       "4              0                  33.0   \n",
       "\n",
       "                                        replyContent      timeToReply  \n",
       "0  Hello BANK Friend, sorry for the issues you’re...  0 days 05:06:00  \n",
       "1  Hello, Friend BANK. Kindly upgrade the BANKApp...  0 days 14:25:00  \n",
       "2  Hello BANK Customer, we appreciate you using t...  0 days 00:41:00  \n",
       "3  Hello BANK Friend, we appreciate your review. ...  0 days 00:30:00  \n",
       "4  Hello BANK Friend, we appreciate your feedback...  0 days 15:05:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df とtest_dfの差分を確認\n",
    "set(train_df.columns) - set(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(636)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"review\"のマックス文字長を確認\n",
    "train_df[\"review\"].str.len().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding操作(テキストのreviewとreplyContentをベクトル化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbDataset(Dataset):\n",
    "    def __init__(self, texts, max_length=650):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        token = self.tokenizer(\n",
    "            self.texts[ix], max_length=self.max_length, padding=\"max_length\", truncation=True, return_token_type_ids=True\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": torch.LongTensor(token[\"input_ids\"]),\n",
    "            \"attention_mask\": torch.LongTensor(token[\"attention_mask\"]),\n",
    "            \"token_type_ids\": torch.LongTensor(token[\"token_type_ids\"]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/274 [00:00<?, ?it/s]/var/folders/29/cqmc7_5s78qf2ttg6l0h0pwr0000gn/T/ipykernel_12901/1863059368.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/Users/iwasakimao/workspace/mufj_signate_mywork/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      " 78%|███████▊  | 213/274 [2:29:47<57:55, 56.98s/it]  "
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "\n",
    "embeddings = {}\n",
    "for key, df in zip([\"train\", \"test\"], [train_df, test_df]):\n",
    "    emb_list_review = []\n",
    "    emb_list_reply = []\n",
    "\n",
    "    dataset_review = EmbDataset(df[\"review\"].values, max_length=650)\n",
    "    dataset_reply = EmbDataset(df[\"replyContent\"].values, max_length=650)\n",
    "\n",
    "    data_loader_review = DataLoader(\n",
    "        dataset_review,\n",
    "        batch_size=32,  # バッチサイズをさらに小さく\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    data_loader_reply = DataLoader(\n",
    "        dataset_reply,\n",
    "        batch_size=32,  # バッチサイズをさらに小さく\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    bar_review = tqdm(enumerate(data_loader_review), total=len(data_loader_review))\n",
    "    for iter_i, batch in bar_review:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            with torch.no_grad():\n",
    "                last_hidden_state, pooler_output = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    return_dict=False,\n",
    "                )\n",
    "            batch_embs = last_hidden_state.mean(dim=1)\n",
    "\n",
    "        emb_list_review.append(batch_embs.detach().cpu().numpy())\n",
    "        del input_ids, attention_mask, token_type_ids, last_hidden_state, pooler_output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    bar_reply = tqdm(enumerate(data_loader_reply), total=len(data_loader_reply))\n",
    "    for iter_i, batch in bar_reply:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            with torch.no_grad():\n",
    "                last_hidden_state, pooler_output = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    return_dict=False,\n",
    "                )\n",
    "            batch_embs = last_hidden_state.mean(dim=1)\n",
    "\n",
    "        emb_list_reply.append(batch_embs.detach().cpu().numpy())\n",
    "        del input_ids, attention_mask, token_type_ids, last_hidden_state, pooler_output\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    embeddings[key] = {\"review\": np.concatenate(emb_list_review), \"replyContent\": np.concatenate(emb_list_reply)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m emb_df\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 埋め込みデータをデータフレームに変換\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m train_review_embeddings_df \u001b[38;5;241m=\u001b[39m embeddings_to_dataframe(\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m train_reply_embeddings_df \u001b[38;5;241m=\u001b[39m embeddings_to_dataframe(embeddings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplyContent\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplyContent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m test_review_embeddings_df \u001b[38;5;241m=\u001b[39m embeddings_to_dataframe(embeddings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train'"
     ]
    }
   ],
   "source": [
    "def embeddings_to_dataframe(embeddings, column_name_prefix):\n",
    "    emb_df = pd.DataFrame(embeddings)\n",
    "    # カラム名に接頭辞をつけて区別する\n",
    "    emb_df.columns = [f\"{column_name_prefix}_emb_{i}\" for i in range(emb_df.shape[1])]\n",
    "    return emb_df\n",
    "\n",
    "\n",
    "# 埋め込みデータをdf変換\n",
    "train_review_embeddings_df = embeddings_to_dataframe(embeddings[\"train\"][\"review\"], \"review\")\n",
    "train_reply_embeddings_df = embeddings_to_dataframe(embeddings[\"train\"][\"replyContent\"], \"replyContent\")\n",
    "test_review_embeddings_df = embeddings_to_dataframe(embeddings[\"test\"][\"review\"], \"review\")\n",
    "test_reply_embeddings_df = embeddings_to_dataframe(embeddings[\"test\"][\"replyContent\"], \"replyContent\")\n",
    "\n",
    "# 埋め込みデータフレームを元dfにマージ\n",
    "train_df = pd.concat([train_df, train_review_embeddings_df, train_reply_embeddings_df], axis=1)\n",
    "test_df = pd.concat([test_df, test_review_embeddings_df, test_reply_embeddings_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴量追加(timeToReplyを数値変換)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_hours(time_str):\n",
    "    if isinstance(time_str, str) and \" days \" in time_str:\n",
    "        try:\n",
    "            days, time = time_str.split(\" days \")\n",
    "            hours, minutes, seconds = map(int, time.split(\":\"))\n",
    "            total_hours = int(days) * 24 + hours + minutes / 60 + seconds / 3600\n",
    "            return total_hours\n",
    "        except ValueError:\n",
    "            return np.nan  # 不正なデータの場合はNaNを返す\n",
    "    else:\n",
    "        return np.nan  # time_strが文字列でないか有効な形式でない場合はNaNを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"total_hours\"] = train_df[\"timeToReply\"].apply(convert_to_hours)\n",
    "test_df[\"total_hours\"] = test_df[\"timeToReply\"].apply(convert_to_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以降学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": 5,\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"learning_rate\": 0.05,  \n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"lambda_l1\": 0.5,  \n",
    "    \"lambda_l2\": 0.5,  # 正則化\n",
    "    \"max_depth\": 4,  \n",
    "    \"num_leaves\": 31, \n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"min_child_samples\": 20,  # 子サンプル数の最小値を増やす\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "except_cols = [\"review\", \"replyContent\", \"timeToReply\", \"score\", \"Unnamed: 0\"]\n",
    "\n",
    "features = [col for col in train_df.columns if col not in except_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optunaでのハイパラチューニングON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "# Optunaの目的関数を定義\n",
    "def objective(trial):\n",
    "    # ハイパーパラメータをOptunaでサンプリング\n",
    "    lgb_params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": 5,\n",
    "        \"metric\": \"multi_logloss\",\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.1),\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 300),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    # 交差検証の設定\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    oof = np.zeros((train_df.shape[0], 5))\n",
    "\n",
    "    # 各フォールドでのモデルのトレーニング\n",
    "    for fold_ix, (trn_, val_) in enumerate(skf.split(train_df, train_df[\"score\"])):\n",
    "        trn_x = train_df.loc[trn_, features]\n",
    "        trn_y = train_df.loc[trn_, \"score\"]\n",
    "        val_x = train_df.loc[val_, features]\n",
    "        val_y = train_df.loc[val_, \"score\"]\n",
    "\n",
    "        trn_data = lgb.Dataset(trn_x, label=trn_y)\n",
    "        val_data = lgb.Dataset(val_x, label=val_y)\n",
    "\n",
    "        # LightGBMモデルのトレーニング\n",
    "        lgb_model = lgb.train(\n",
    "            lgb_params,\n",
    "            trn_data,\n",
    "            valid_sets=[trn_data, val_data],\n",
    "            num_boost_round=10000,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)],\n",
    "        )\n",
    "\n",
    "        # 検証データに対する予測\n",
    "        oof[val_] = lgb_model.predict(val_x)\n",
    "\n",
    "    # multi_loglossを計算\n",
    "    oof_labels = np.argmax(oof, axis=1)\n",
    "    score = log_loss(train_df[\"score\"], oof)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "# Optunaで最適化\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# 最適なハイパーパラメータを出力\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "# 最適なハイパーパラメータでモデルを再トレーニング\n",
    "best_params = trial.params\n",
    "best_params.update({\"objective\": \"multiclass\", \"num_class\": 5, \"metric\": \"multi_logloss\", \"seed\": 42})\n",
    "lgb_params = best_params\n",
    "\n",
    "# モデルの再トレーニングと予測\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "oof = np.zeros((train_df.shape[0], 5))\n",
    "preds = np.zeros((test_df.shape[0], 5))\n",
    "\n",
    "for fold_ix, (trn_, val_) in enumerate(skf.split(train_df, train_df[\"score\"])):\n",
    "    trn_x = train_df.loc[trn_, features]\n",
    "    trn_y = train_df.loc[trn_, \"score\"]\n",
    "    val_x = train_df.loc[val_, features]\n",
    "    val_y = train_df.loc[val_, \"score\"]\n",
    "\n",
    "    trn_data = lgb.Dataset(trn_x, label=trn_y)\n",
    "    val_data = lgb.Dataset(val_x, label=val_y)\n",
    "\n",
    "    lgb_model = lgb.train(\n",
    "        lgb_params,\n",
    "        trn_data,\n",
    "        valid_sets=[trn_data, val_data],\n",
    "        num_boost_round=10000,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(100)],\n",
    "    )\n",
    "\n",
    "    oof[val_] = lgb_model.predict(val_x)\n",
    "    preds += lgb_model.predict(test_df[features]) / skf.n_splits\n",
    "\n",
    "oof_labels = np.argmax(oof, axis=1)\n",
    "preds_labels = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用ファイルを作成.2️列目を書き換える\n",
    "sub_df = pd.read_csv(\"../input/sample_submission.csv\", header=None)\n",
    "sub_df[1] = preds_labels\n",
    "sub_df.to_csv(\"sub_emb_opt.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
